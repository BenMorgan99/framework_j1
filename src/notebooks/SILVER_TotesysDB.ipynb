{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b12ff3c-2e6f-442f-977c-295ddbb2b306",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./Configuration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b282c9c-af9f-4884-9c85-396ca8bc2049",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Variables"
    }
   },
   "outputs": [],
   "source": [
    "# Define the metadata widget:\n",
    "dbutils.widgets.text(\"entityName\", \"\")\n",
    "dbutils.widgets.text(\"entityColumns\", \"\")\n",
    "dbutils.widgets.text(\"sourceSystem\", \"\")\n",
    "\n",
    "# Save parameters to variables:\n",
    "entityName =       dbutils.widgets.get('entityName')\n",
    "sourceSystemName = dbutils.widgets.get('sourceSystem')\n",
    "columns =          json.loads(dbutils.widgets.get('entityColumns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "968e9560-257c-4e51-b2b1-8176a4bcf192",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "entityNames"
    }
   },
   "outputs": [],
   "source": [
    "# Define query to extract entityNames from sourceSystem table:\n",
    "query = f\"\"\"\n",
    "  SELECT entityNames\n",
    "  FROM   sourceSystem\n",
    "  WHERE  sourceEntityName = '{sourceSystemName}'\n",
    "  \"\"\"\n",
    "\n",
    "# Extract the array from entityNames DataFrame and convert to list:\n",
    "entity_names = json.loads(([row.entityNames for row in query_db(query).collect()])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6081f5f3-71fd-443b-a217-fb79d36e7c09",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create DataFrames"
    }
   },
   "outputs": [],
   "source": [
    "# For each entity, create a dataFrame:\n",
    "for entity in entity_names:\n",
    "   # Read from BRONZE path in datalake:\n",
    "   globals()[f\"df_{entity}\"] = spark.read.format('parquet').load(BRONZE + f'/TotesysDB/{entity}/{datetime.datetime.now().strftime(\"%Y/%m/%d\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfc65b7e-1b7d-4359-bc66-e04d8d23a8b7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create TempViews"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate through entities to create temp views:\n",
    "for entity in entity_names:\n",
    "    # Create or replace tempView:\n",
    "    globals()[f'df_{entity}'].createOrReplaceTempView(f\"tv_{entity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c93906a-c939-49b2-87af-a0a809003b1d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dim_date"
    }
   },
   "outputs": [],
   "source": [
    "if entityName == 'date':\n",
    "    dbutils.notebook.exit('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23c54663-c6c5-4790-a5c3-aa4b12abf7fc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dim_design"
    }
   },
   "outputs": [],
   "source": [
    "if entityName == 'design':\n",
    "    \n",
    "    # Define Dynamic Query:\n",
    "    query = f\"\"\"\n",
    "    SELECT CAST(design_id AS {columns[0]['dataType']}) AS {columns[0]['columnName']}\n",
    "    ,      CAST(design_name AS {columns[1]['dataType']}) AS {columns[1]['columnName']}\n",
    "    ,      CAST(file_location AS {columns[2]['dataType']}) AS {columns[2]['columnName']}\n",
    "    ,      CAST(file_name AS {columns[3]['dataType']}) AS {columns[3]['columnName']}\n",
    "    FROM tv_design\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute Query:\n",
    "    df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a3a2372-6748-448a-98ca-dba159660582",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dim_transaction"
    }
   },
   "outputs": [],
   "source": [
    "if entityName == 'transaction':\n",
    "    query = f\"\"\"\n",
    "    SELECT CAST(transaction_id AS {columns[0]['dataType']}) AS {columns[0]['columnName']}\n",
    "    ,      CAST(transaction_type AS {columns[1]['dataType']}) AS {columns[1]['columnName']}\n",
    "    ,      CAST(sales_order_id AS {columns[2]['dataType']}) AS {columns[2]['columnName']}\n",
    "    ,      CAST(purchase_order_id AS {columns[3]['dataType']}) AS {columns[3]['columnName']}\n",
    "    FROM tv_transaction\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute Query:\n",
    "    df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c8bd49f-c89f-452f-a971-a49d754d31e6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dim_payment_type"
    }
   },
   "outputs": [],
   "source": [
    "if entityName == 'payment_type':\n",
    "    query = f\"\"\"\n",
    "    SELECT CAST(payment_type_id AS {columns[0]['dataType']}) AS {columns[0]['columnName']}\n",
    "    ,      CAST(payment_type_name AS {columns[1]['dataType']}) AS {columns[1]['columnName']}\n",
    "    FROM tv_payment_type\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute Query:\n",
    "    df = spark.sql(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e9f45a4-d5a4-43f7-967d-92878d5c9965",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dim_location"
    }
   },
   "outputs": [],
   "source": [
    "if entityName == 'location':\n",
    "    query = f\"\"\"\n",
    "    SELECT CAST(address_id AS {columns[0]['dataType']}) AS {columns[0]['columnName']}\n",
    "    ,      CAST(address_line_1 AS {columns[1]['dataType']}) AS {columns[1]['columnName']}\n",
    "    ,      CAST(address_line_2 AS {columns[2]['dataType']}) AS {columns[2]['columnName']}\n",
    "    ,      CAST(district AS {columns[3]['dataType']}) AS {columns[3]['columnName']}\n",
    "    ,      CAST(city AS {columns[4]['dataType']}) AS {columns[4]['columnName']}\n",
    "    ,      CAST(postal_code AS {columns[5]['dataType']}) AS {columns[5]['columnName']}\n",
    "    ,      CAST(country AS {columns[6]['dataType']}) AS {columns[6]['columnName']}\n",
    "    ,      CAST(phone AS {columns[7]['dataType']}) AS {columns[7]['columnName']}\n",
    "    FROM tv_location\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute Query:\n",
    "    df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d582cdd1-21dd-4cdc-b4eb-4b241888f767",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dim_currency"
    }
   },
   "outputs": [],
   "source": [
    "if entityName == 'currency':\n",
    "    query = f\"\"\"\n",
    "    SELECT CAST(currency_id AS {columns[0]['dataType']}) AS {columns[0]['columnName']}\n",
    "    ,      {columns[1]['dataType']}(currency_code) AS {columns[1]['columnName']}\n",
    "    ,      CASE \n",
    "                WHEN currency_code = 'USD' THEN 'United States Dollar'\n",
    "                WHEN currency_code = 'EUR' THEN 'Euro'\n",
    "                WHEN currency_code = 'JPY' THEN 'Japanese Yen'\n",
    "                WHEN currency_code = 'GBP' THEN 'British Pound Sterling'\n",
    "                WHEN currency_code = 'AUD' THEN 'Australian Dollar'\n",
    "                WHEN currency_code = 'CAD' THEN 'Canadian Dollar'\n",
    "                WHEN currency_code = 'CHF' THEN 'Swiss Franc'\n",
    "                WHEN currency_code = 'CNY' THEN 'Chinese Yuan'\n",
    "                WHEN currency_code = 'NZD' THEN 'New Zealand Dollar'\n",
    "                ELSE 'Unknown Currency'\n",
    "           END AS {columns[2]['columnName']}   \n",
    "    FROM tv_currency\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute Query:\n",
    "    df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ba51ea1-7baa-4005-81bc-54ec26e46efa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dim_counterparty"
    }
   },
   "outputs": [],
   "source": [
    "if entityName == 'counterparty':\n",
    "    query = f\"\"\"\n",
    "    SELECT CAST(cp.counterparty_id AS {columns[0]['dataType']}) AS {columns[0]['columnName']}\n",
    "    ,      CAST(cp.counterparty_legal_name AS {columns[1]['dataType']}) AS {columns[1]['columnName']}\n",
    "    ,      CAST(l.address_line_1 AS {columns[2]['dataType']}) AS {columns[2]['columnName']}\n",
    "    ,      CAST(l.address_line_2 AS {columns[3]['dataType']}) AS {columns[3]['columnName']}\n",
    "    ,      CAST(l.district AS {columns[4]['dataType']}) AS {columns[4]['columnName']}\n",
    "    ,      CAST(l.city AS {columns[5]['dataType']}) AS {columns[5]['columnName']}\n",
    "    ,      CAST(l.postal_code AS {columns[6]['dataType']}) AS {columns[6]['columnName']}\n",
    "    ,      CAST(l.country AS {columns[7]['dataType']}) AS {columns[7]['columnName']}\n",
    "    ,      CAST(l.phone AS {columns[8]['dataType']}) AS {columns[8]['columnName']}\n",
    "    FROM tv_counterparty cp\n",
    "    JOIN tv_location l ON cp.legal_address_id = l.address_id\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute Query:\n",
    "    df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a216d92-72bb-47e4-9599-69f94eefbee3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dim_department"
    }
   },
   "outputs": [],
   "source": [
    "if entityName == 'department':\n",
    "    query = f\"\"\"\n",
    "    SELECT CAST(department_id AS {columns[0]['dataType']}) AS {columns[0]['columnName']}\n",
    "    ,      CAST(department_name AS {columns[1]['dataType']}) AS {columns[1]['columnName']}\n",
    "    ,      CAST(location AS {columns[2]['dataType']}) AS {columns[2]['columnName']}\n",
    "    ,      CAST(manager AS {columns[3]['dataType']}) AS {columns[3]['columnName']}\n",
    "    ,      CAST(created_at AS {columns[4]['dataType']}) AS {columns[4]['columnName']}\n",
    "    ,      CAST(last_updated AS {columns[5]['dataType']}) AS {columns[5]['columnName']}\n",
    "    FROM tv_department\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute Query:\n",
    "    df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "907d330f-e1ed-4c73-9bae-ea296ca66722",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dim_staff"
    }
   },
   "outputs": [],
   "source": [
    "if entityName == 'staff':\n",
    "    query = f\"\"\"\n",
    "    SELECT CAST(s.staff_id AS {columns[0]['dataType']}) AS {columns[0]['columnName']}\n",
    "    ,      CAST(s.first_name AS {columns[1]['dataType']}) AS {columns[1]['columnName']}\n",
    "    ,      CAST(s.last_name AS {columns[2]['dataType']}) AS {columns[2]['columnName']}\n",
    "    ,      CAST(d.department_name AS {columns[3]['dataType']}) AS {columns[3]['columnName']}\n",
    "    ,      CAST(d.location AS {columns[4]['dataType']}) AS {columns[4]['columnName']}\n",
    "    ,      CAST(s.email_address AS {columns[5]['dataType']}) AS {columns[5]['columnName']}\n",
    "    FROM tv_staff s\n",
    "    JOIN tv_department d ON s.department_id = d.department_id\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute Query:\n",
    "    df = spark.sql(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc65941b-5035-48ad-8361-81b2b865cba1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "fact_payment"
    }
   },
   "outputs": [],
   "source": [
    "if entityName == 'payment':\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "          ROW_NUMBER() OVER (ORDER BY {columns[1]['columnName']}) as {columns[0]['columnName']}\n",
    "        , CAST(p.payment_id AS {columns[1]['dataType']}) AS {columns[1]['columnName']}\n",
    "        , CAST(p.created_at AS {columns[2]['dataType']}) AS {columns[2]['columnName']}\n",
    "        , CAST(date_format(p.created_at, 'HH:mm:ss') AS STRING) AS {columns[3]['columnName']}\n",
    "        , CAST(p.last_updated AS {columns[4]['dataType']}) AS {columns[4]['columnName']}\n",
    "        , CAST(date_format(p.last_updated, 'HH:mm:ss') AS STRING) AS {columns[5]['columnName']}\n",
    "        , CAST(t.transaction_id AS {columns[6]['dataType']}) AS {columns[6]['columnName']}\n",
    "        , CAST(cp.counterparty_id AS {columns[7]['dataType']}) AS {columns[7]['columnName']}\n",
    "        , CAST(p.payment_amount AS DECIMAL(10,2)) AS {columns[8]['columnName']}\n",
    "        , CAST(c.currency_id AS {columns[9]['dataType']}) AS {columns[9]['columnName']}\n",
    "        , CAST(pt.payment_type_id AS {columns[10]['dataType']}) AS {columns[10]['columnName']}\n",
    "        , CAST(p.paid AS {columns[11]['dataType']}) AS {columns[11]['columnName']}\n",
    "      --  , CAST(p.payment_date AS {columns[12]['dataType']}) AS {columns[12]['columnName']}\n",
    "    FROM tv_payment p\n",
    "    JOIN tv_counterparty cp ON p.counterparty_id = cp.counterparty_id\n",
    "    JOIN tv_currency c ON p.currency_id = c.currency_id\n",
    "    JOIN tv_payment_type pt ON p.payment_type_id = pt.payment_type_id\n",
    "    JOIN tv_transaction t ON p.transaction_id = t.transaction_id\n",
    "    \"\"\"\n",
    " \n",
    "    # Execute Query:\n",
    "    df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a102e594-16b9-416c-ae83-50f6c57b35ff",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "fact_purchase_order"
    }
   },
   "outputs": [],
   "source": [
    "if entityName == 'purchase_order':\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "           ROW_NUMBER() OVER (ORDER BY po.{columns[1]['columnName']}) as {columns[0]['columnName']}\n",
    "    ,      CAST(po.purchase_order_id AS {columns[1]['dataType']}) AS {columns[1]['columnName']}\n",
    "    ,      CAST(po.created_at AS {columns[2]['dataType']}) AS {columns[2]['columnName']}\n",
    "    ,      CAST(date_format(po.created_at, 'HH:mm:ss') AS STRING) AS {columns[3]['columnName']}  \n",
    "    ,      CAST(po.last_updated AS {columns[4]['dataType']}) AS {columns[4]['columnName']}\n",
    "    ,      CAST(date_format(po.last_updated, 'HH:mm:ss') AS STRING) AS {columns[5]['columnName']}\n",
    "    ,      CAST(s.staff_id AS {columns[6]['dataType']}) AS {columns[6]['columnName']}\n",
    "    ,      CAST(cp.counterparty_id AS {columns[7]['dataType']}) AS {columns[7]['columnName']}\n",
    "    ,      CAST(po.item_code AS {columns[8]['dataType']}) AS {columns[8]['columnName']}\n",
    "    ,      CAST(po.item_quantity AS {columns[9]['dataType']}) AS {columns[9]['columnName']}\n",
    "    ,      CAST(po.item_unit_price AS DECIMAL(10,2)) AS {columns[10]['columnName']}\n",
    "    ,      CAST(c.currency_id AS {columns[11]['dataType']}) AS {columns[11]['columnName']}\n",
    "    ,      CAST(po.agreed_delivery_date AS {columns[12]['dataType']}) AS {columns[12]['columnName']}\n",
    "    ,      CAST(po.agreed_payment_date AS {columns[13]['dataType']}) AS {columns[13]['columnName']}\n",
    "    ,      CAST(l.address_id AS {columns[14]['dataType']}) AS {columns[14]['columnName']}\n",
    "\n",
    "    FROM tv_purchase_order po\n",
    "       JOIN tv_staff        s      ON po.staff_id = s.staff_id \n",
    "       JOIN tv_counterparty cp     ON po.counterparty_id = cp.counterparty_id\n",
    "       JOIN tv_currency     c      ON po.currency_id = c.currency_id\n",
    "       JOIN tv_location     l      ON po.agreed_delivery_location_id = l.address_id\n",
    "   \n",
    "    \"\"\"\n",
    "\n",
    "    # Execute Query:\n",
    "    df = spark.sql(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c51aa481-a487-47cf-8bee-24ce5a48f7df",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "fact_sales_order"
    }
   },
   "outputs": [],
   "source": [
    "if entityName == 'sales_order':\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "           ROW_NUMBER() OVER (ORDER BY so.{columns[1]['columnName']}) as {columns[0]['columnName']}\n",
    "    ,      CAST(so.sales_order_id AS {columns[1]['dataType']}) AS {columns[1]['columnName']}\n",
    "    ,      CAST(so.created_at AS {columns[2]['dataType']}) AS {columns[2]['columnName']}\n",
    "    ,      CAST(date_format(so.created_at, 'HH:mm:ss') AS STRING) AS {columns[3]['columnName']}\n",
    "    ,      CAST(so.last_updated AS {columns[4]['dataType']}) AS {columns[4]['columnName']}\n",
    "    ,      CAST(date_format(so.last_updated, 'HH:mm:ss') AS STRING) AS {columns[5]['columnName']}\n",
    "    ,      CAST(s.staff_id AS {columns[6]['dataType']}) AS {columns[6]['columnName']}\n",
    "    ,      CAST(cp.counterparty_id AS {columns[7]['dataType']}) AS {columns[7]['columnName']}\n",
    "    ,      CAST(so.units_sold AS {columns[8]['dataType']}) AS {columns[8]['columnName']}\n",
    "    ,      CAST(so.unit_price AS {columns[9]['dataType']}) AS {columns[9]['columnName']}\n",
    "    ,      CAST(c.currency_id AS {columns[10]['dataType']}) AS {columns[10]['columnName']}\n",
    "    ,      CAST(d.design_id AS {columns[11]['dataType']}) AS {columns[11]['columnName']}\n",
    "    ,      CAST(so.agreed_payment_date AS {columns[12]['dataType']}) AS {columns[12]['columnName']}\n",
    "    ,      CAST(so.agreed_delivery_date AS {columns[13]['dataType']}) AS {columns[13]['columnName']}\n",
    "    ,      CAST(l.address_id AS {columns[14]['dataType']}) AS {columns[14]['columnName']}\n",
    "    FROM tv_sales_order so\n",
    "    JOIN tv_counterparty cp ON so.counterparty_id = cp.counterparty_id\n",
    "    JOIN tv_staff s ON so.staff_id = s.staff_id\n",
    "    JOIN tv_currency c ON so.currency_id = c.currency_id\n",
    "    JOIN tv_design d ON so.design_id = d.design_id\n",
    "    JOIN tv_location l on so.agreed_delivery_location_id = l.address_id\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute Query:\n",
    "    df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a56b7eb-4aee-46c7-a83c-13bc4964dbff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check data exists:\n",
    "if df.count() > 0:\n",
    "    folder_path = datetime.datetime.now().strftime(\"%Y/%m/%d\")\n",
    "\n",
    "    # Set location for delta table:\n",
    "    location = SILVER + f\"/{sourceSystemName}/{entityName}/{folder_path}/\"\n",
    "    \n",
    "    # Write to delta table:\n",
    "    df.write.mode('overwrite').format('delta').option('header', 'true').save(location)\n",
    "\n",
    "    # Output location:\n",
    "    dbutils.notebook.exit(location)\n",
    "else:\n",
    "    dbutils.notebook.exit(-1)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5936656170437836,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "SILVER_TotesysDB",
   "widgets": {
    "entityColumns": {
     "currentValue": "[{\"sortOrder\": 1, \"columnName\": \"design_id\", \"dataType\": \"int\"}, {\"sortOrder\": 2, \"columnName\": \"design_name\", \"dataType\": \"string\"}, {\"sortOrder\": 3, \"columnName\": \"file_location\", \"dataType\": \"string\"}, {\"sortOrder\": 4, \"columnName\": \"file_name\", \"dataType\": \"string\"}]",
     "nuid": "64e27337-10d6-4ff1-ad73-11c5eee59eb7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "entityColumns",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "entityColumns",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "entityName": {
     "currentValue": "design",
     "nuid": "ce268007-f490-4643-ac59-e91eb16e75d1",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "entityName",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "entityName",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "sourceSystem": {
     "currentValue": "TotesysDB",
     "nuid": "8812902f-648d-44eb-897c-f6edce76ff30",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "sourceSystem",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "sourceSystem",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
